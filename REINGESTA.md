# ğŸ”„ GuÃ­a de Reingesta de Documentos

Esta guÃ­a explica cÃ³mo reiniciar el sistema y hacer una reingesta completa de documentos.

---

## ğŸ“‹ Escenarios de uso

### OpciÃ³n 1: Reingesta completa (resetear todo y volver a empezar)

Usa esto cuando:
- Quieres que el sistema "olvide" todo lo aprendido
- Has actualizado/modificado los documentos RAW
- Quieres cambiar la configuraciÃ³n de chunking o embeddings

**Pasos:**

```bash
# 1. Resetear la base de conocimientos
python reset_knowledge.py

# 2. (Opcional) Actualizar documentos en data/raw/

# 3. Ejecutar reingesta completa
python reingest.py

# 4. Reiniciar el servidor FastAPI
# Ctrl+C en la terminal del servidor y volver a ejecutar:
uvicorn src.service.app:app --reload
```

---

### OpciÃ³n 2: Solo actualizar documentos (mantener vector store existente)

Usa esto cuando:
- Solo quieres agregar nuevos documentos sin borrar los existentes
- Los documentos existentes no han cambiado

**Pasos:**

```bash
# 1. Agregar nuevos documentos a data/raw/

# 2. Procesar documentos
python -m src.knowledge_base.ingest

# 3. Actualizar vector store (agregarÃ¡ los nuevos chunks)
python reingest.py

# 4. Reiniciar el servidor FastAPI
```

---

## ğŸ“ Estructura de directorios

```
org-assistant/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # ğŸ“‚ Coloca tus documentos aquÃ­
â”‚   â”‚   â”œâ”€â”€ politicas/
â”‚   â”‚   â”‚   â””â”€â”€ politica_datos.txt
â”‚   â”‚   â”œâ”€â”€ procedimientos/
â”‚   â”‚   â”‚   â””â”€â”€ reembolsos.md
â”‚   â”‚   â””â”€â”€ incidentes/
â”‚   â”‚       â””â”€â”€ casos_historicos.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                # ğŸ“ Documentos procesados (chunks)
â”‚   â”‚   â””â”€â”€ knowledge_chunks.jsonl
â”‚   â”‚
â”‚   â””â”€â”€ embeddings/               # ğŸ—„ï¸ Vector store (embeddings)
â”‚       â””â”€â”€ chroma/
â”‚           â””â”€â”€ chroma.sqlite3
```

---

## ğŸ› ï¸ Formatos de documentos soportados

- `.txt` - Archivos de texto plano
- `.md` - Markdown
- `.pdf` - PDFs (requiere `pypdf`)
- `.docx` - Word (requiere `docx2txt`)
- `.csv` - CSV (se convierte a tabla de texto)
- `.json` - JSON (se formatea con indentaciÃ³n)

---

## âš™ï¸ Personalizar la ingesta

### Cambiar el tamaÃ±o de los chunks

Edita [src/knowledge_base/ingest.py:36-40](src/knowledge_base/ingest.py#L36-L40):

```python
DEFAULT_SPLITTER = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # â† Cambiar aquÃ­ (caracteres por chunk)
    chunk_overlap=150,    # â† Solapamiento entre chunks
    separators=["\n\n", "\n", " ", ""],
)
```

### Cambiar el modelo de embeddings

Edita [.env](.env):

```bash
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2  # Modelo actual (rÃ¡pido, inglÃ©s)
# Alternativas:
# EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2  # MultilingÃ¼e
# EMBEDDING_MODEL=BAAI/bge-base-en-v1.5  # Mejor calidad, mÃ¡s lento
```

**Nota:** Si cambias el modelo de embeddings, DEBES hacer una reingesta completa (OpciÃ³n 1).

---

## ğŸ” Verificar el estado del sistema

```bash
# Ver quÃ© documentos estÃ¡n en RAW
ls data/raw/

# Ver cuÃ¡ntos chunks se procesaron
python -c "import json; chunks = open('data/processed/knowledge_chunks.jsonl').readlines(); print(f'{len(chunks)} chunks procesados')"

# Verificar que el vector store existe
ls data/embeddings/chroma/

# Probar el sistema end-to-end
python test_api.py
```

---

## âš ï¸ SoluciÃ³n de problemas

### Error: "No se encontraron documentos en la carpeta raw/"

**SoluciÃ³n:** Coloca al menos un documento soportado en `data/raw/`

### Error: "El vector store no se ha inicializado"

**SoluciÃ³n:** Ejecuta `python reingest.py` para construir el vector store

### Error al cargar PDFs o DOCX

**SoluciÃ³n:** Instala las dependencias faltantes:

```bash
pip install pypdf docx2txt
```

### El sistema no refleja los cambios en los documentos

**SoluciÃ³n:** Ejecuta una reingesta completa (OpciÃ³n 1) y reinicia el servidor

---

## ğŸ“Š Metadata de los documentos

Cada chunk incluye automÃ¡ticamente:

- `source`: Ruta relativa del documento
- `document_id`: Nombre del archivo (sin extensiÃ³n)
- `process`: Nombre de la carpeta padre (ej: "politicas", "procedimientos")
- `chunk_id`: ID Ãºnico del chunk
- `keywords`: Palabras clave extraÃ­das con TF-IDF

Puedes usar estos campos para filtrar bÃºsquedas desde Streamlit.

---

## ğŸ¯ Mejores prÃ¡cticas

1. **Organiza tus documentos por proceso** en subcarpetas de `data/raw/` (ej: `politicas/`, `rrhh/`, `ti/`)
   - Esto permite filtrar por proceso en las bÃºsquedas

2. **Usa nombres descriptivos** para los archivos
   - El nombre se usa como `document_id` en los metadatos

3. **MantÃ©n los documentos actualizados** en `data/raw/`
   - Nunca modifiques `data/processed/` o `data/embeddings/` manualmente

4. **Haz backup de `data/raw/`** antes de cambios importantes
   - Es la Ãºnica fuente de verdad del sistema

5. **Reinicia el servidor** despuÃ©s de cada reingesta
   - El servidor cachea el vector store en memoria

---

## ğŸš€ Flujo de trabajo recomendado

```bash
# 1. Desarrollo: Actualizar documentos
# Edita/agrega archivos en data/raw/

# 2. Hacer reingesta
python reingest.py

# 3. Probar el sistema
python test_api.py

# 4. Si los tests pasan, reiniciar servidor
# Ctrl+C en terminal del servidor
uvicorn src.service.app:app --reload

# 5. Probar desde Streamlit
streamlit run src/ui/app.py
```

---

## ğŸ“ Scripts disponibles

| Script | DescripciÃ³n |
|--------|-------------|
| `reset_knowledge.py` | Elimina vector store y procesados (mantiene RAW) |
| `reingest.py` | Procesa documentos y construye vector store |
| `test_api.py` | DiagnÃ³stico completo del sistema |

---

Â¿Dudas? Revisa los logs del sistema o ejecuta `python test_api.py` para diagnÃ³stico detallado.
