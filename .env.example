# =============================================================================
# CONFIGURACIÓN DEL ASISTENTE ORGANIZACIONAL - MODELO LOCAL
# =============================================================================
# Copia este archivo a .env y ajusta según necesites

# -----------------------------------------------------------------------------
# Ollama (Modelo LLM Local)
# -----------------------------------------------------------------------------
# URL del servidor Ollama (por defecto corre en localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Modelo LLM a usar (debe estar descargado con 'ollama pull')
# Recomendado: llama3.1:8b-instruct-q4_K_M (balance calidad/velocidad, ~5GB)
# Alternativas:
#   - llama3.2:3b (más rápido, menor calidad, ~2GB)
#   - mistral:7b (bueno en razonamiento, ~4GB)
#   - qwen2.5:7b (excelente multilingüe, ~5GB)
OLLAMA_MODEL=llama3.1:8b-instruct-q4_K_M

# -----------------------------------------------------------------------------
# Modelo de Embeddings (Local - Sentence Transformers)
# -----------------------------------------------------------------------------
# Modelo recomendado para español/multilingüe:
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Alternativas (requieren más RAM pero mejor calidad):
# - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (mejor español)
# - BAAI/bge-base-en-v1.5 (mejor calidad general, más lento)

# -----------------------------------------------------------------------------
# Rutas de datos
# -----------------------------------------------------------------------------
VECTOR_STORE_PATH=data/embeddings/chroma
KNOWLEDGE_BASE_PATH=data/processed
RAW_DATA_PATH=data/raw

# -----------------------------------------------------------------------------
# Configuración del servidor
# -----------------------------------------------------------------------------
SERVICE_HOST=0.0.0.0
SERVICE_PORT=8000
STREAMLIT_PORT=8501

# -----------------------------------------------------------------------------
# CORS y API URLs
# -----------------------------------------------------------------------------
ALLOWED_ORIGINS=http://localhost:8501,http://127.0.0.1:8501
API_BASE_URL=http://localhost:8000
