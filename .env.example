# =============================================================================
# CONFIGURACIÓN DEL ASISTENTE ORGANIZACIONAL
# =============================================================================
# Copia este archivo a .env y completa con tus valores reales

# -----------------------------------------------------------------------------
# API de Groq (Modelo generativo)
# -----------------------------------------------------------------------------
# Obtén tu API key en: https://console.groq.com/keys
GROQ_API_KEY=tu_api_key_aqui

# Modelo recomendado: llama-3.3-70b-versatile
# Otros modelos disponibles: llama-3.1-8b-instant, mixtral-8x7b-32768
GROQ_MODEL=llama-3.3-70b-versatile

# -----------------------------------------------------------------------------
# Modelo de Embeddings
# -----------------------------------------------------------------------------
# Modelo recomendado para español/multilingüe:
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Alternativas:
# - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (mejor para español)
# - BAAI/bge-base-en-v1.5 (mejor calidad, más lento)

# -----------------------------------------------------------------------------
# Rutas de datos
# -----------------------------------------------------------------------------
VECTOR_STORE_PATH=data/embeddings/chroma
KNOWLEDGE_BASE_PATH=data/processed
RAW_DATA_PATH=data/raw

# -----------------------------------------------------------------------------
# Configuración del servidor
# -----------------------------------------------------------------------------
SERVICE_HOST=0.0.0.0
SERVICE_PORT=8000
STREAMLIT_PORT=8501

# -----------------------------------------------------------------------------
# CORS y API URLs
# -----------------------------------------------------------------------------
ALLOWED_ORIGINS=http://localhost:8501,http://127.0.0.1:8501
API_BASE_URL=http://localhost:8000
